<!DOCTYPE html>
<html class="dark" lang="en">

<head>
    <meta charset="utf-8" />
    <meta content="width=device-width, initial-scale=1.0" name="viewport" />
    <title>Rude AI Voice Assistant</title>
    <meta name="description" content="Talk to the world's rudest AI assistant — if you dare." />
    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect" />
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300;400;500;600;700&display=swap"
        rel="stylesheet" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons+Round" rel="stylesheet" />
    <style>
        /* ═══════════════════════════════════════════════════════════
           DESIGN SYSTEM — Dark Cyberpunk Voice UI
           ═══════════════════════════════════════════════════════════ */
        :root {
            --primary: #0db9f2;
            --primary-dark: #0a9acb;
            --primary-glow: rgba(13, 185, 242, 0.35);
            --bg: #101e22;
            --bg-card: #152228;
            --bg-input: #0e191d;
            --text: #e2e8f0;
            --text-muted: #64748b;
            --border: #1e3a42;
            --red: #ef4444;
            --red-glow: rgba(239, 68, 68, 0.4);
            --font: 'Space Grotesk', system-ui, sans-serif;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html,
        body {
            height: 100%;
            width: 100%;
            overflow: hidden;
            font-family: var(--font);
            background: var(--bg);
            color: var(--text);
        }

        body {
            display: flex;
            flex-direction: column;
            position: relative;
        }

        /* ── Texture overlay ── */
        body::before {
            content: '';
            position: fixed;
            inset: 0;
            background: url('https://www.transparenttextures.com/patterns/dark-matter.png');
            opacity: 0.08;
            pointer-events: none;
            z-index: 0;
            mix-blend-mode: overlay;
        }

        /* ── Header ── */
        .header {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 100;
            padding: 20px 32px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: linear-gradient(180deg, var(--bg) 70%, transparent);
        }

        .status-badge {
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .status-dot {
            position: relative;
            width: 10px;
            height: 10px;
        }

        .status-dot span {
            position: absolute;
            inset: 0;
            border-radius: 50%;
            background: var(--primary);
        }

        .status-dot .ping {
            animation: ping 1.5s cubic-bezier(0, 0, 0.2, 1) infinite;
            opacity: 0.75;
        }

        @keyframes ping {

            75%,
            100% {
                transform: scale(2.2);
                opacity: 0;
            }
        }

        .status-text {
            font-size: 0.8rem;
            font-weight: 500;
            letter-spacing: 0.15em;
            text-transform: uppercase;
            color: var(--text-muted);
        }

        /* ── Main Content ── */
        .main-area {
            flex: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative;
            z-index: 1;
            padding: 80px 24px 140px;
            gap: 28px;
            overflow-y: auto;
        }

        /* ── Mic Button ── */
        .mic-container {
            position: relative;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 16px;
        }

        .mic-glow {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 280px;
            height: 280px;
            border-radius: 50%;
            background: radial-gradient(circle, var(--primary-glow) 0%, transparent 70%);
            opacity: 0;
            transition: opacity 0.5s;
            pointer-events: none;
        }

        .mic-container:hover .mic-glow,
        .mic-container.recording .mic-glow {
            opacity: 1;
        }

        .mic-container.recording .mic-glow {
            background: radial-gradient(circle, var(--red-glow) 0%, transparent 70%);
            animation: pulse-glow 1.5s ease-in-out infinite;
        }

        @keyframes pulse-glow {

            0%,
            100% {
                opacity: 0.6;
                transform: translate(-50%, -50%) scale(1);
            }

            50% {
                opacity: 1;
                transform: translate(-50%, -50%) scale(1.15);
            }
        }

        .mic-ring {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 220px;
            height: 220px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--primary) 0%, transparent 60%);
            opacity: 0.2;
            filter: blur(8px);
            pointer-events: none;
        }

        .mic-btn {
            position: relative;
            width: 200px;
            height: 200px;
            border-radius: 50%;
            border: 1.5px solid var(--border);
            background: radial-gradient(circle at 30% 30%, #1e2f34, var(--bg));
            box-shadow: 0 0 40px rgba(0, 0, 0, 0.5), inset 0 1px 0 rgba(255, 255, 255, 0.03);
            cursor: pointer;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            gap: 12px;
            transition: transform 0.15s, border-color 0.3s, box-shadow 0.3s;
            animation: idle-pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite;
            outline: none;
        }

        @keyframes idle-pulse {

            0%,
            100% {
                box-shadow: 0 0 20px 0 rgba(13, 185, 242, 0.2);
            }

            50% {
                box-shadow: 0 0 50px 8px rgba(13, 185, 242, 0.45);
            }
        }

        .mic-btn:hover {
            transform: scale(1.03);
            border-color: var(--primary);
        }

        .mic-btn:active {
            transform: scale(0.96);
        }

        .mic-btn .inner-ring {
            position: absolute;
            inset: 8px;
            border-radius: 50%;
            border: 1px solid rgba(255, 255, 255, 0.04);
            pointer-events: none;
        }

        .mic-btn .mic-icon {
            font-size: 56px;
            color: var(--primary);
            filter: drop-shadow(0 0 18px rgba(13, 185, 242, 0.8));
            transition: color 0.3s, filter 0.3s;
        }

        .mic-btn .mic-label {
            font-size: 0.68rem;
            font-weight: 700;
            letter-spacing: 0.2em;
            text-transform: uppercase;
            color: rgba(13, 185, 242, 0.7);
            transition: color 0.3s;
        }

        /* Recording state */
        .mic-container.recording .mic-btn {
            border-color: var(--red);
            animation: recording-pulse 1s ease-in-out infinite;
        }

        .mic-container.recording .mic-btn .mic-icon {
            color: var(--red);
            filter: drop-shadow(0 0 18px var(--red-glow));
        }

        .mic-container.recording .mic-btn .mic-label {
            color: var(--red);
        }

        @keyframes recording-pulse {

            0%,
            100% {
                box-shadow: 0 0 20px 0 var(--red-glow);
            }

            50% {
                box-shadow: 0 0 50px 12px var(--red-glow);
            }
        }

        /* Disabled / thinking state */
        .mic-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            animation: none;
        }

        /* ── State Pill ── */
        .state-pill {
            font-size: 0.92rem;
            font-weight: 500;
            color: var(--text-muted);
            transition: color 0.3s;
            min-height: 24px;
        }

        .state-pill.listening {
            color: var(--red);
            animation: blink 1s infinite;
        }

        .state-pill.thinking {
            color: #f59e0b;
            animation: blink 0.8s infinite;
        }

        .state-pill.speaking {
            color: var(--primary);
            animation: blink 1.2s infinite;
        }

        @keyframes blink {

            0%,
            100% {
                opacity: 1;
            }

            50% {
                opacity: 0.3;
            }
        }

        /* ── Instructions ── */
        .instructions {
            text-align: center;
            color: var(--text-muted);
            font-size: 0.92rem;
            line-height: 1.8;
            max-width: 500px;
        }

        .kbd {
            display: inline-block;
            background: var(--bg-input);
            border: 1px solid var(--border);
            border-radius: 5px;
            padding: 1px 8px;
            font-family: monospace;
            font-size: 0.75rem;
            color: var(--primary);
            margin: 0 2px;
        }



        /* ── Waveform Footer ── */
        .waveform-footer {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            height: 100px;
            display: flex;
            align-items: flex-end;
            justify-content: center;
            gap: 3px;
            padding-bottom: 16px;
            opacity: 0.6;
            pointer-events: none;
            z-index: 0;
        }

        .wave-bar {
            width: 5px;
            border-radius: 9999px;
            background: linear-gradient(to top, var(--primary), rgba(13, 185, 242, 0.08));
            transition: height 0.3s;
        }

        /* Wave animation */
        @keyframes wave {

            0%,
            100% {
                height: 16%;
            }

            50% {
                height: 75%;
            }
        }

        /* ── Ended screen ── */
        .ended-screen {
            text-align: center;
        }

        .ended-screen h2 {
            font-size: 1.6rem;
            font-weight: 300;
            color: var(--text-muted);
            margin-bottom: 10px;
        }

        .ended-screen p {
            color: var(--text-muted);
            opacity: 0.6;
            font-size: 0.9rem;
        }

        .ended-screen button {
            margin-top: 24px;
            background: var(--primary);
            color: #000;
            border: none;
            border-radius: 12px;
            padding: 14px 32px;
            font-family: var(--font);
            font-size: 0.95rem;
            font-weight: 600;
            cursor: pointer;
            transition: background 0.2s;
        }

        .ended-screen button:hover {
            background: var(--primary-dark);
        }

        /* ── Responsiveness ── */
        @media (max-width: 640px) {
            .mic-btn {
                width: 160px;
                height: 160px;
            }

            .mic-btn .mic-icon {
                font-size: 44px;
            }

            .mic-glow {
                width: 220px;
                height: 220px;
            }

            .mic-ring {
                width: 180px;
                height: 180px;
            }

            .header {
                padding: 14px 18px;
            }
        }
    </style>
</head>

<body>
    <!-- Header -->
    <header class="header">
        <div class="status-badge">
            <div class="status-dot">
                <span class="ping"></span>
                <span></span>
            </div>
            <span class="status-text" id="headerStatus">System Online</span>
        </div>
    </header>

    <!-- Main Content -->
    <main class="main-area" id="mainArea">
        <!-- Mic Button -->
        <div class="mic-container" id="micContainer">
            <div class="mic-glow"></div>
            <div class="mic-ring"></div>
            <button class="mic-btn" id="micBtn" title="Tap to talk">
                <div class="inner-ring"></div>
                <span class="material-icons-round mic-icon" id="micIcon">mic</span>
                <span class="mic-label" id="micLabel">Tap to Talk</span>
            </button>
        </div>

        <!-- State Pill -->
        <div class="state-pill" id="statePill">Ready</div>

        <!-- Chat Log -->
        <div class="chat-log" id="chatLog"></div>

        

        <!-- Instructions -->
        <div class="instructions">
            Press <span class="kbd">Space</span> to interrupt &middot;
            Say <strong style="color:var(--text);">&ldquo;Goodbye&rdquo;</strong> to end conversation
        </div>
    </main>

    <!-- Waveform Footer -->
    <div class="waveform-footer" id="waveform"></div>

    <!-- Hidden audio player -->
    <audio id="audioPlayer" style="display:none;"></audio>

    <script>
        (() => {
            // ── DOM refs ──
            const micBtn = document.getElementById('micBtn');
            const micContainer = document.getElementById('micContainer');
            const micIcon = document.getElementById('micIcon');
            const micLabel = document.getElementById('micLabel');
            const statePill = document.getElementById('statePill');
            const audioPlayer = document.getElementById('audioPlayer');
            const headerStatus = document.getElementById('headerStatus');
            const waveformEl = document.getElementById('waveform');
            const mainArea = document.getElementById('mainArea');

            // ── State ──
            let state = 'idle'; // idle | listening | thinking | speaking | ended
            let conversationActive = false; // true once user clicks mic to start the loop
            let micStream = null; // persistent mic stream
            let mediaRecorder = null;
            let audioChunks = [];
            let currentAudio = null;
            let silenceTimer = null;
            let analyser = null;
            let audioContext = null;

            // Silence detection config
            const SILENCE_THRESHOLD = 15; // RMS level below which = silence
            const SILENCE_DURATION = 2000; // ms of silence before auto-stop
            const MIN_RECORDING_TIME = 500; // ms minimum recording before silence detection kicks in

            // ── Generate waveform bars ──
            const BAR_COUNT = 30;
            for (let i = 0; i < BAR_COUNT; i++) {
                const bar = document.createElement('div');
                bar.className = 'wave-bar';
                const h = 8 + Math.random() * 55;
                const dur = (0.8 + Math.random() * 0.8).toFixed(2);
                const delay = (Math.random() * 0.5).toFixed(2);
                bar.style.height = `${h}%`;
                bar.style.animation = `wave ${dur}s ease-in-out ${delay}s infinite`;
                waveformEl.appendChild(bar);
            }

            // ── State machine ──
            function setState(newState, message) {
                state = newState;
                statePill.className = 'state-pill ' + newState;

                switch (newState) {
                    case 'idle':
                        statePill.textContent = message || 'Ready — tap mic to start conversation';
                        micBtn.disabled = false;
                        micContainer.classList.remove('recording');
                        micIcon.textContent = 'mic';
                        micLabel.textContent = 'Tap to Talk';
                        headerStatus.textContent = 'System Online';
                        conversationActive = false;
                        break;
                    case 'listening':
                        statePill.textContent = message || 'Listening... (speak now)';
                        micBtn.disabled = true;
                        micContainer.classList.add('recording');
                        micIcon.textContent = 'graphic_eq';
                        micLabel.textContent = 'Listening';
                        headerStatus.textContent = 'Listening';
                        break;
                    case 'thinking':
                        statePill.textContent = message || 'Thinking...';
                        micBtn.disabled = true;
                        micContainer.classList.remove('recording');
                        micIcon.textContent = 'hourglass_top';
                        micLabel.textContent = 'Processing';
                        headerStatus.textContent = 'Processing';
                        break;
                    case 'speaking':
                        statePill.textContent = message || 'Speaking...';
                        micBtn.disabled = true;
                        micContainer.classList.remove('recording');
                        micIcon.textContent = 'volume_up';
                        micLabel.textContent = 'Speaking';
                        headerStatus.textContent = 'Speaking';
                        break;
                    case 'ended':
                        conversationActive = false;
                        releaseMic();
                        mainArea.innerHTML = `
                        <div class="ended-screen">
                            <h2>Conversation Ended</h2>
                            <p>The AI has had enough of you.</p>
                            <button onclick="location.reload()">Start New Conversation</button>
                        </div>`;
                        headerStatus.textContent = 'Offline';
                        break;
                }
            }


            // ── Play audio ──
            function playAudio(base64Wav) {
                return new Promise((resolve) => {
                    if (!base64Wav) { resolve(); return; }
                    setState('speaking');
                    const blob = base64ToBlob(base64Wav, 'audio/wav');
                    const url = URL.createObjectURL(blob);
                    audioPlayer.src = url;
                    audioPlayer.onended = () => {
                        URL.revokeObjectURL(url);
                        resolve();
                    };
                    audioPlayer.onerror = () => { resolve(); };
                    currentAudio = audioPlayer;
                    audioPlayer.play().catch(() => resolve());
                });
            }

            function base64ToBlob(b64, mime) {
                const bin = atob(b64);
                const bytes = new Uint8Array(bin.length);
                for (let i = 0; i < bin.length; i++) bytes[i] = bin.charCodeAt(i);
                return new Blob([bytes], { type: mime });
            }

            // ═══════════════════════════════════════════════════════
            // CONTINUOUS VOICE LOOP
            // ═══════════════════════════════════════════════════════

            // Acquire mic stream once and keep it alive for the session
            async function acquireMic() {
                if (micStream) return micStream;
                micStream = await navigator.mediaDevices.getUserMedia({ audio: true });

                // Setup audio analyser for silence detection
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(micStream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 512;
                source.connect(analyser);

                return micStream;
            }

            function releaseMic() {
                if (micStream) {
                    micStream.getTracks().forEach(t => t.stop());
                    micStream = null;
                }
                if (audioContext) {
                    audioContext.close().catch(() => { });
                    audioContext = null;
                    analyser = null;
                }
                clearTimeout(silenceTimer);
            }

            // Start recording with automatic silence detection
            function startListening() {
                if (!micStream || !conversationActive) return;

                audioChunks = [];
                mediaRecorder = new MediaRecorder(micStream, { mimeType: 'audio/webm;codecs=opus' });

                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) audioChunks.push(e.data);
                };

                mediaRecorder.onstop = async () => {
                    if (!conversationActive) return;
                    if (audioChunks.length === 0) {
                        // No audio — re-listen
                        if (conversationActive) startListening();
                        return;
                    }
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await processVoice(audioBlob);
                };

                mediaRecorder.start(250); // collect in 250ms chunks
                setState('listening');

                // Start silence detection after a brief delay
                const recordStartTime = Date.now();
                monitorSilence(recordStartTime);
            }

            // Monitor audio levels and auto-stop on silence
            function monitorSilence(recordStartTime) {
                if (!analyser || !conversationActive || state !== 'listening') return;

                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                let silenceStart = null;

                function check() {
                    if (!conversationActive || state !== 'listening') return;

                    analyser.getByteTimeDomainData(dataArray);

                    // Calculate RMS
                    let sum = 0;
                    for (let i = 0; i < dataArray.length; i++) {
                        const val = (dataArray[i] - 128) / 128;
                        sum += val * val;
                    }
                    const rms = Math.sqrt(sum / dataArray.length) * 100;

                    const elapsed = Date.now() - recordStartTime;

                    if (rms < SILENCE_THRESHOLD && elapsed > MIN_RECORDING_TIME) {
                        if (!silenceStart) silenceStart = Date.now();
                        if (Date.now() - silenceStart >= SILENCE_DURATION) {
                            // Silence detected — stop recording
                            stopListening();
                            return;
                        }
                    } else {
                        silenceStart = null; // reset on sound
                    }

                    requestAnimationFrame(check);
                }

                requestAnimationFrame(check);
            }

            function stopListening() {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                    setState('thinking');
                }
            }

            // ── Process voice → API → play response → auto re-listen ──
            async function processVoice(blob) {
                setState('thinking');
                try {
                    const form = new FormData();
                    form.append('file', blob, 'recording.webm');

                    const res = await fetch('/api/chat', { method: 'POST', body: form });
                    const data = await res.json();

                    if (!res.ok) {
                        // Could not understand — auto re-listen
                        if (conversationActive) {
                            setState('listening', 'Could not understand — listening again...');
                            setTimeout(() => { if (conversationActive) startListening(); }, 500);
                        }
                        return;
                    }



                    // Play TTS response
                    if (data.audio) {
                        await playAudio(data.audio);
                    }

                    // Check for goodbye
                    if (data.is_goodbye) {
                        setState('ended');
                        return;
                    }

                    // ── AUTO RE-LISTEN → this is the continuous loop ──
                    if (conversationActive) {
                        startListening();
                    }
                } catch (err) {
                    console.error('API Error:', err);
                    // On error, try to keep the loop going
                    if (conversationActive) {
                        setState('listening', 'Connection error — listening again...');
                        setTimeout(() => { if (conversationActive) startListening(); }, 1000);
                    }
                }
            }

            // ── Start the conversation loop (called once on mic click) ──
            async function beginConversation() {
                try {
                    await acquireMic();
                    conversationActive = true;
                    startListening();
                } catch (err) {
                    setState('idle', 'Mic access denied — use text input below');
                    console.error('Mic error:', err);
                }
            }

            // ── Stop entire conversation ──
            function endConversation() {
                conversationActive = false;
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                }
                if (currentAudio && !currentAudio.paused) {
                    currentAudio.pause();
                    currentAudio.currentTime = 0;
                }
                releaseMic();
                setState('ended');
            }



            // ── Interrupt playback (Space key) ──
            function interrupt() {
                if (currentAudio && !currentAudio.paused) {
                    currentAudio.pause();
                    currentAudio.currentTime = 0;
                    // After interrupt, auto re-listen if in conversation
                    if (conversationActive) {
                        startListening();
                    } else {
                        setState('idle', 'Interrupted — tap mic to restart');
                    }
                }
            }

            // ── Event Listeners ──
            micBtn.addEventListener('click', () => {
                if (state === 'idle' && !conversationActive) {
                    beginConversation();
                }
            });

            // Keyboard shortcuts
            document.addEventListener('keydown', (e) => {
                // Space to interrupt (when not typing)
                if (e.key === ' ' && e.target.tagName !== 'INPUT' && e.target.tagName !== 'TEXTAREA') {
                    e.preventDefault();
                    if (state === 'speaking') {
                        interrupt();
                    }
                }
            });

            // Init
            setState('idle', 'Ready — tap mic to start conversation');
        })();
    </script>
</body>

</html>